{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60344e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code which demonstrates a simple Neural Network for MNIST Dataset from Scratch without using Tensorflow or Pytorch. Purely using numpy.\n",
    "# I have included the comments everywhere to understand the relationship between the mathematical aspects and the equations involved in the code (These comments were manually written by me for understanding)\n",
    "#Imports\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16336b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MNIST dataset\n",
    "#return_X_Y = True means it will return the feature matrix, kind of a pixel data and y kinda returns the different digits from 0-9\n",
    "#as_frame = False means it will return it as a numpy arrays rather than pandas dataframes since we are implementing a Neural Network using Numpy.\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542b2111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape) # The Dataset contains 70000 images and each image is of 28 x 28 pixels therefore 28 x 28 = 784 pixels flattened therefore shape (70000, 784)\n",
    "print(y.shape) # There are 70000 labels, one for each image therefore shape (70000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce548bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prints the first image of the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = X[0].reshape(28,28)\n",
    "plt.imshow(image, cmap = \"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a21159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAACRBJREFUeJzt3DloVesexuG1r8FC0UgaBUFEC0VFbFQ4CCIiImgRtQlYKVYKVjZ2FhHBoQhapArYiKVDo4VTIQji0ATslXQajTOafZvLyyku3PzXuRmMz1Ovl7UQsn98hV+n2+12GwBomuZfs/0BAMwdogBAiAIAIQoAhCgAEKIAQIgCACEKAETPVB/sdDrT+R0ATLOp/F9lJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAKJntj8A/pcFCxaUN729vdPwJf8fJ0+ebLVbtGhRebNu3bry5sSJE+XNxYsXy5uBgYHypmma5tu3b+XN+fPny5uzZ8+WN/OBkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAuBBvnlm1alV5s3DhwvLmr7/+Km927NhR3jRN0yxbtqy8OXToUKt3zTdv3rwpb4aGhsqb/v7+8mZiYqK8aZqmefXqVXnz6NGjVu/6EzkpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAESn2+12p/RgpzPd38LfbNmypdXu/v375U1vb2+rdzGzJicny5ujR4+WN58+fSpv2hgbG2u1e//+fXnz+vXrVu+ab6byc++kAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4JXWO6uvra7V7+vRpebNmzZpW75pv2vzbjY+Plze7du0qb5qmaX78+FHeuAGXv3NLKgAlogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgBEz2x/AP/du3fvWu1Onz5d3uzfv7+8efHiRXkzNDRU3rT18uXL8mbPnj3lzefPn8ubjRs3ljdN0zSnTp1qtYMKJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA6HS73e6UHux0pvtbmCVLly4tbyYmJsqb4eHh8qZpmubYsWPlzZEjR8qb69evlzfwO5nKz72TAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAED0zPYHMPs+fvw4I+/58OHDjLynaZrm+PHj5c2NGzfKm8nJyfIG5jInBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQCi0+12u1N6sNOZ7m9hnlu8eHGr3e3bt8ubnTt3ljf79u0rb+7du1fewGyZys+9kwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAuBCPOW/t2rXlzfPnz8ub8fHx8ubBgwflzbNnz8qbpmmaq1evljdT/PPmD+FCPABKRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIF+IxL/X395c3IyMj5c2SJUvKm7bOnDlT3ly7dq28GRsbK2/4PbgQD4ASUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDChXjwH5s2bSpvLl++XN7s3r27vGlreHi4vBkcHCxv3r59W94w81yIB0CJKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDhQjz4B5YtW1beHDhwoNW7RkZGyps2f7f3798vb/bs2VPeMPNciAdAiSgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhFtS4Tfx/fv38qanp6e8+fnzZ3mzd+/e8ubhw4flDf+MW1IBKBEFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIOq3ZcE8tXnz5vLm8OHD5c3WrVvLm6Zpd7ldG6Ojo+XN48ePp+FLmA1OCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDhQjzmvHXr1pU3J0+eLG8OHjxY3qxYsaK8mUm/fv0qb8bGxsqbycnJ8oa5yUkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIFyIRyttLoIbGBho9a42l9utXr261bvmsmfPnpU3g4OD5c2tW7fKG+YPJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAcCHePLN8+fLyZsOGDeXNlStXypv169eXN3Pd06dPy5sLFy60etfNmzfLm8nJyVbv4s/lpABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAuCV1BvT19ZU3w8PDrd61ZcuW8mbNmjWt3jWXPXnypLy5dOlSeXP37t3y5uvXr+UNzBQnBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYD4oy/E2759e3lz+vTp8mbbtm3lzcqVK8ubue7Lly+tdkNDQ+XNuXPnypvPnz+XNzDfOCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxB99IV5/f/+MbGbS6OhoeXPnzp3y5ufPn+XNpUuXypumaZrx8fFWO6DOSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgOt1utzulBzud6f4WAKbRVH7unRQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgOiZ6oPdbnc6vwOAOcBJAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgPg3RRQ2Q9xu2TsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAB4ZJREFUeJzt3KGK1G0Dh+EZ2SAYXkWDWPQIZA9gg2ERBYNpq56ATbBYbIJJRKtiN3gAopbFQ1iLYDCMyWAyzP9L380Hrx/Ms++M6/peV54f8xTn3if4zKdpmmYAMJvNThz1AQD4fYgCABEFACIKAEQUAIgoABBRACCiAEC2Vv3gfD7f5DkA2LBV/q+ymwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgDZOuoDAJtz//794c2DBw+GNydOjP99eeXKleHNbDabvX///lA7VuOmAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUA4kE8OCZu3749vLl3797wZrlcDm8OY5qmX/I9jHFTACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA8SAeHBMXL14c3pw8eXIDJ+FP5qYAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDEK6nwi+3u7h5qd+fOnTWf5OcODg6GNzdu3BjeLBaL4Q2b56YAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQDiQTz4B3Z2doY3z58/P9R3/fXXX4fajXr06NHw5vPnzxs4CUfBTQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAMSDePAP3Lp1a3hz4cKFDZzk5969eze8efny5foPwrHhpgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFADKfpmla6YPz+abPAkfq3Llzw5vFYjG8WS6Xw5vZbDb79u3b8GZvb2948/bt2+ENx8MqP/duCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQLaO+gCwCZcuXRrevHr1av0HWaMnT54Mb7x4yig3BQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEA/i8Ue6du3a8Oby5csbOMnfvXnz5lC7x48fr/kk8HduCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIPNpmqaVPjifb/os8FM3b94c3rx48WJ4c+rUqeHN/v7+8GZvb294M5vNZovF4lA7+K9Vfu7dFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQLaO+gD8e1y6dOlQu1evXq33IGv06dOn4Y2H7fiduSkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYB4EI9f5t69e4faLZfLNZ9kfR4+fHjUR4C1clMAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQDilVQOZXt7e3hz9erV9R9kjV6/fj28+fjx4wZOAkfHTQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAGQ+TdO00gfn802fhWPk69evw5szZ85s4CQ/9+HDh+HN9evXhzffv38f3sBRWeXn3k0BgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBk66gPwPF09uzZ4c1yudzASX7u2bNnwxuP24GbAgD/QxQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACAexGP2/Pnz4c2JE7/33xP7+/tHfQQ4ln7vf9kA/FKiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA8SDeH2Z7e3t4s7u7O7xZLpfDmx8/fgxvZrPZ7OnTp8ObxWJxqO+Cfzs3BQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIF5J/cOcPn16eHP+/Pn1H+Qnvnz5cqjd3bt313wS4P9xUwAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgW0d9ANbr4OBgeLO/vz+82dnZGd4Avz83BQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkPk0TdNKH5zPN30WADZolZ97NwUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYBsrfrBaZo2eQ4AfgNuCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoA5D8je6wCC0/TuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prints the first 5 images of the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(5):\n",
    "    image = X[i].reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"grey\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "772140c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images from (0,255) pixel range 0 indicating black and 255 indicating white to [0, 1] range as Neural Networks converge better in this range\n",
    "X = X/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16c3af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# This check ensures that the X is normalized [0, 1] range as it is observed the max pixel value is 1 and min pixel value is 0 \n",
    "print(X[50000][:40])\n",
    "print(X.min())\n",
    "print(X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e31cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset y type <class 'str'>\n",
      "Updated y type <class 'numpy.int64'>\n",
      "Dimensions of original y array 1\n",
      "Shape of original array (70000,)\n",
      "Dimensions of updated y array 2\n",
      "Shape of new array (70000, 1)\n",
      "Original label [5]\n",
      "OHE label [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding is to be done since the models dont really work with raw labels therefore it needs to be converted to a OHE Vector as in \n",
    "# for vector y = 5, its OHE representation will be [0,0,0,0,0,1,0,0,0,0]\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "print(\"Dataset y type\", type(y[0])) #Type was  string\n",
    "#Since the y i.e, the class labels are in String type so we typecast the string labels to int labels for OHE\n",
    "y = y.astype(int)\n",
    "print(\"Updated y type\", type(y[0])) # Type became int\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "print(\"Dimensions of original y array\", y.ndim)\n",
    "print(\"Shape of original array\", y.shape) # Y is a 1D array (70000,)\n",
    "#As y is a 1D array, it is not possible to do OHE on it directly, therefore we somehow need to convert it to a 2D array\n",
    "#Since the shape of the y is (70000,), its 1D, therefore we can just append a 1 to it simply to make it a 2D array OHE can run on it. Thats what the next line does\n",
    "y = y.reshape(-1, 1)\n",
    "print(\"Dimensions of updated y array\", y.ndim) \n",
    "print(\"Shape of new array\", y.shape)# Now Y is a 2D array (70000,1)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_hot = encoder.fit_transform(y)\n",
    "print(\"Original label\", y[0])  \n",
    "print(\"OHE label\", y_hot[0])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c96c2d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape (56000, 784)\n",
      "X test shape (14000, 784)\n",
      "y train shape (56000, 10)\n",
      "y test shape (14000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Next we will do the train test split of the dataset. We will perform a 80-20 split of the dataset. 80% of the data will be sent for training and 20% will be sent for testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y_hot, test_size=0.2, random_state=42)\n",
    "print(\"X train shape\", X_train.shape)\n",
    "print(\"X test shape\", X_test.shape)\n",
    "print(\"y train shape\", y_train.shape)\n",
    "print(\"y test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c5a5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Till now the data preprocessing stage is done, some of the steps to summarize which were done are:\n",
    "# 1. Fetching the MNIST dataset.\n",
    "# 2. Normalizing the pixel values to [0, 1] range.\n",
    "# 3. One Hot Encoding the labels. (Also involved the conversion of labels from string to int + reshaping the labels to 2D array for OHE compatibility)\n",
    "# 4. Splitting the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7126acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the architecture of the Neural Network that will be implemented:\n",
    "# 2 Layer Neural Network\n",
    " \n",
    "#        Layer                            Size                                   Activation Function\n",
    "#     Input Layer            784 (28x28 pixels flattened)                                ----\n",
    "#     Hidden Layer                        128                                           ReLU\n",
    "#     Output Layer                         10                                           Softmax\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a901fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We first define the structure of the NN. As discussed above, the Input Size is 784 (28x 28 pixels flattened), Hidden Layer size is 128 it can be adjusted to any value and output size is 10 (0-9 digits)\n",
    "input_size = 784\n",
    "hidden_size = 128\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ac10ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define the weights and biases for the network.\n",
    "# Initialization matters a lot in NNs, so we will be using the \"He initialization\" method for the weights.\n",
    "# The formula for He initialization is:\n",
    "# Var(W) = 2 / n_in, where n_in is the number of inputs to the layer.\n",
    "# It is commonly used for ReLU activation functions . Given the rigid nature of ReLU, it is important as it provides kind of a compensation since ReLU nearly zeroes out 50% of the inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e4927f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights and biases from the input layer to the hidden layer\n",
    "W1 = np.random.randn(hidden_size, input_size) * np.sqrt(2 / input_size) # Standard deviation is square root of variance.\n",
    "b1 = np.zeros((hidden_size, 1)) # Let's initialize the bias value of each hidden neuron to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6319ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights and biases from the hidden layer to the output layer\n",
    "W2 = np.random.randn(output_size, hidden_size) * np.sqrt(2/ hidden_size)\n",
    "b2 = np.zeros((output_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99f28f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 784)\n",
      "(128, 1)\n",
      "(10, 128)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(W1.shape) #Weights from the input Layer to the hidden Layer but written as (hidden_size, input_size) (128, 784)\n",
    "print(b1.shape) #Biases for 128 hidden neurons (128,1) 1 means it's applied to a single input.\n",
    "print(W2.shape) # Weights from the hidden layer to the output layer but written as (output_size, hidden_size) (10, 128)\n",
    "print(b2.shape) # Biases for 10 output neurons (10,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a780a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical Definition of ReLU Activation Function:\n",
    "# ReLU is defined as:\n",
    "# ReLU(x) = max(0,x)\n",
    "# ReLU'(x) (Derivative of ReLU) = 1 if x > 0 else 0\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    return (Z > 0).astype(float)\n",
    "# The return function of ReLU derivative is exactly how the actual ReLU derivative activation function is defined. Let's understand it with an example:\n",
    "# Supppose Z = [-2, 0, 3], Z > 0 creates a boolean array [False, False, True] now we have to convert it to values like 0 and 1, therefore we use astype (float) which converts the boolean array\n",
    "# to [0.0, 0.0, 1.0] which is exactly the ReLU derivative activation function for the given Z. \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "262cc0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Shape:  (1, 3)\n",
      "After applying ReLU Activation Function:  [[0 0 3]]\n",
      "After applying ReLU Derivative Activation Function:  [[0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# ReLU activation function and its derivative function check for random np array.\n",
    "Z = np.array([[-2, 0, 3]])\n",
    "print(\"Z Shape: \", Z.shape)\n",
    "print(\"After applying ReLU Activation Function: \", relu(Z))\n",
    "print(\"After applying ReLU Derivative Activation Function: \", relu_derivative(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mathematical Definition of Softmax Activation Function:\n",
    "# Softmax is defined as:\n",
    "# Softmax(z(i)) = e ^ (z(i) - max(z)) / summation(e ^ (z(j) - max(z))) for all j\n",
    "\n",
    "#Why SoftMax?\n",
    "# Softmax is commonly used in the output layer of the multi class classification problems as it converts the raw scores into probabilities that sum up to 1.\n",
    "# The subtraction of max(z) is done to prevent overflow issues when computing the exponentials, as it can grow huge for large values of Z. So its incorporated in the formula itself. \n",
    "\n",
    "def softmax(Z):\n",
    "    Z_stable = Z - np.max(Z, axis=0, keepdims=True) # This is the ( z(i) - max(z) ) part of the softmax expression in the numerator, axis = 0 implies we are doing for each row  which means each column is treated as a sample and keepdims = True ensures the output has the same dimeensions as output.\n",
    "    exp_Z = np.exp(Z_stable) # We have raised the expression to the power of e, these two steps comprise the numerator of the expression\n",
    "    softmax_output = exp_Z / np.sum(exp_Z, axis=0, keepdims=True) # This is the entire softmax expression \n",
    "    return softmax_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9cfcb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying Softmax Activation Function:  [[0.00637746]\n",
      " [0.04712342]\n",
      " [0.94649912]]\n"
     ]
    }
   ],
   "source": [
    "#Softmax activation function check for random np array.\n",
    "Z = np.array([[-2, 0, 3]]).T\n",
    "print(\"After applying Softmax Activation Function: \", softmax(Z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0461296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we implement the forward pass of the NN\n",
    "# Given the input X, weights W1 and W2, corresponding biases b1 and b2, the forward propagation is defined as follows:\n",
    "# Z1 = W1 * X + b1\n",
    "# A1 = ReLU(Z1)\n",
    "# Z2 - W2 * A1 + b2\n",
    "# A2 = Softmax(Z2)\n",
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the cross-entropy loss function for the output layer.\n",
    "# The cross-entropy loss function is defined as:\n",
    "# Loss = - summation (i = 1 to C) (y (i)) * log(y'(i)) for all i where y(i) is the true label and y'(i) is the predicted probability by softmax for the sample of a given class i. For more than 1 sample,  we divide it by 'm', where 'm' is the total number of samples, so formula becomes:\n",
    "# Loss = -1/m * summation (j = 1 to m) (i = 1 to C) (y (i)) * log(y'(i)) for all i\n",
    "# If you would manually like to compute, its basically you are considering the only the true labels with value of 1 and multiplying with its corresponding log of predicted probability and summing it up over all examples. \n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0] # Why shape[0] ? Because the losses are computed over the number of samples, and number of samples corresponds to axis = 0, which spans through all the rows.\n",
    "    loss = -1/m * np.sum(y_true * np.log(y_pred + 1e-8)) # We added a small epsilon value of 1e-8 so that we do not run into log 0 and crash training.\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "1\n",
      "1\n",
      "Cross-Entropy Loss:  1.6094378624341017\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([[0, 0, 1, 0, 0, 0]])\n",
    "y_pred = np.array([[0.1, 0.8, 0.2, 0.1, 0.1, 0.1]])\n",
    "print(y_true.shape[1])  # General rule is shape[1] gives the number of columns which corresponds to the number of classes\n",
    "print(y_pred.shape[1])\n",
    "print(y_true.shape[0])  # General rule is shape[0] gives the number of rows which corresponds to the number of samples\n",
    "print(y_pred.shape[0])\n",
    "#But Cross-Entropy Loss is computed over the number of samples, therefore we use shape[0] for y_true and y_pred\n",
    "print(\"Cross-Entropy Loss: \", cross_entropy_loss((y_true), (y_pred)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
